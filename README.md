# ğŸš€ End-to-End Machine Learning API

An end-to-end production-ready API that serves machine learning predictions with robust features including authentication, Redis caching, Prometheus monitoring, and Dockerized deployment. Built using **FastAPI**.

Demo Link: https://end-to-end-car-price-prediction.onrender.com

---

## ğŸ“š Table of Contents

- [Project Overview](#project-overview)  
- [Features](#features)  
- [Project Structure](#project-structure)  
- [Setup Instructions](#setup-instructions)  
- [Running the Application](#running-the-application)  
- [API Endpoints](#api-endpoints)  
- [Authentication](#authentication)  
- [Model Training](#model-training)  
- [Caching](#caching)  
- [Monitoring](#monitoring)  
- [Deployment](#deployment)  
- [Additional Notes](#additional-notes)  

---

## ğŸ“Œ Project Overview

This project provides an **End-to-End API** for serving machine learning predictions.  
Key components include:

- JWT-based authentication  
- Model inference using a pre-trained ML model  
- Redis caching for performance  
- Prometheus for real-time monitoring  
- Docker for deployment  

---

## âœ¨ Features

- âœ… **User Authentication** (JWT-based)  
- ğŸ¤– **ML Model Serving** (`joblib` model)  
- âš¡ **Prediction Caching** (Redis)  
- ğŸ“ **Logging Middleware**  
- ğŸ“Š **Prometheus Monitoring**  
- ğŸ“¦ **Dockerized Deployment**

---

## ğŸ—ï¸ Project Structure

```
End-to-End API/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/                # API route definitions
â”‚   â”‚   â”œâ”€â”€ routes_auth.py
â”‚   â”‚   â””â”€â”€ routes_predict.py
â”‚   â”œâ”€â”€ cache/              # Redis caching logic
â”‚   â”‚   â””â”€â”€ redis_cache.py
â”‚   â”œâ”€â”€ core/               # Config, security, exception handling
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ dependencies.py
â”‚   â”‚   â”œâ”€â”€ exceptions.py
â”‚   â”‚   â””â”€â”€ security.py
â”‚   â”œâ”€â”€ middleware/         # Logging middleware
â”‚   â”‚   â””â”€â”€ logging_middleware.py
â”‚   â”œâ”€â”€ models/             # Trained ML model
â”‚   â”‚   â””â”€â”€ model.joblib
â”‚   â”œâ”€â”€ services/           # Model inference logic
â”‚   â”‚   â””â”€â”€ model_service.py
â”‚   â””â”€â”€ main.py             # FastAPI app entry point
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ car-details.csv     # Sample dataset
â”‚
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ train_model.py      # Training script
â”‚   â””â”€â”€ train_utils.py
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ sample.ipynb        # EDA & prototyping
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ prometheus.yml
â”œâ”€â”€ render.yaml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup Instructions

### ğŸ”§ Prerequisites

- Python 3.8+
- Redis (locally or via Docker)
- Docker & Docker Compose (for containerized setup)

### ğŸ› ï¸ Installation

```bash
# 1. Clone the Repository
git clone <repo-url>
cd End-to-End\ API

# 2. Create Virtual Environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 3. Install Dependencies
pip install -r requirements.txt

# 4. Set Up Environment Variables
# Create a `.env` file in app/ if needed

# Example .env
SECRET_KEY=your_secret_key
REDIS_URL=redis://localhost:6379/0
```

---

## ğŸš€ Running the Application

### ğŸ§ª Option 1: Local Development

Start Redis server manually if not using Docker:
```bash
redis-server
```

Run the FastAPI app:
```bash
uvicorn app.main:app --reload
```

Access it at: [http://localhost:8000](http://localhost:8000)

---

### ğŸ³ Option 2: Docker Compose

```bash
docker-compose up --build
```

This will start:

- FastAPI application  
- Redis server  
- Prometheus server (if configured)  

---

## ğŸ“¡ API Endpoints

| Method | Endpoint         | Description                        |
|--------|------------------|------------------------------------|
| POST   | `/auth/login`    | User authentication (returns JWT) |
| POST   | `/predict`       | Make prediction (JWT required)     |
| GET    | `/metrics`       | Prometheus metrics                 |

---

## ğŸ” Authentication

- JWT is used for securing routes.  
- Use `/auth/login` to get the token.  
- Add token to protected requests using header:

```http
Authorization: Bearer <your_token>
```

---

## ğŸ§  Model Training

- Scripts are located in `training/`
- To retrain the model:
```bash
python training/train_model.py
```
- The trained model is saved to `app/models/model.joblib`

---

## âš¡ Caching

- Redis is used to cache predictions.
- Caching logic is implemented in `app/cache/redis_cache.py`.

---

## ğŸ“ˆ Monitoring

- Prometheus configuration is in `prometheus.yml`.
- Metrics exposed at: [http://localhost:8000/metrics](http://localhost:8000/metrics)

---

## ğŸš€ Deployment

### Docker

```bash
docker-compose up --build
```

### Render (Cloud)

- `render.yaml` provided for Render.com deployment.
- Setup environment variables in Render dashboard.

---

## ğŸ“ Additional Notes

- ğŸ§ª **Jupyter Notebooks**: For EDA and prototyping in `notebooks/`.
- ğŸ§¾ **Logging**: Custom middleware logs all incoming requests (`app/middleware/logging_middleware.py`).
- âš™ï¸ **Config**: Centralized settings in `app/core/config.py`.

---
